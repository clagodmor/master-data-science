{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGboost modelling\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "train_df = pd.read_csv('data/train.csv', header=0)\n",
    "test_df = pd.read_csv('data/test.csv', header=0)\n",
    "valitade_df = pd.read_csv('data/validate.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll impute missing values using the median for numeric columns and the most\n",
    "# common value for string columns.\n",
    "from sklearn.base import TransformerMixin\n",
    "class DataFrameImputer(TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.fill = pd.Series([X[c].value_counts().index[0]\n",
    "            if X[c].dtype == np.dtype('O') else X[c].median() for c in X],\n",
    "            index=X.columns)\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns_to_use = ['wind','demand','photo','temp','thermo','hydro_disp','hydro_prod']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the features from train and test together before imputing missing values,\n",
    "# in case their distribution is slightly different\n",
    "big_X = train_df[feature_columns_to_use].append(test_df[feature_columns_to_use])\n",
    "big_X_imputed = DataFrameImputer().fit_transform(big_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the inputs for the model\n",
    "train_X = big_X_imputed[0:train_df.shape[0]].values\n",
    "test_X = big_X_imputed[train_df.shape[0]::].values\n",
    "train_y = train_df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n"
     ]
    }
   ],
   "source": [
    "#Fitting XGB regressor \n",
    "model = xgb.XGBRegressor()\n",
    "model.fit(train_X,train_y)\n",
    "print (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Date     Price\n",
      "0     2018-01-29 13:00:00  6.448314\n",
      "1     2016-10-13 15:00:00  5.334073\n",
      "2     2015-09-20 16:00:00  4.488747\n",
      "3     2014-08-25 03:00:00  4.712053\n",
      "4     2017-09-06 00:00:00  4.546413\n",
      "5     2017-07-30 00:00:00  4.568891\n",
      "6     2018-02-24 15:00:00  5.884620\n",
      "7     2015-12-21 17:00:00  6.091932\n",
      "8     2017-03-14 04:00:00  2.754140\n",
      "9     2014-03-24 13:00:00  3.661605\n",
      "10    2018-04-23 05:00:00  4.120895\n",
      "11    2014-06-06 22:00:00  3.616781\n",
      "12    2017-05-20 00:00:00  4.560211\n",
      "13    2014-12-07 22:00:00  4.511248\n",
      "14    2017-02-23 15:00:00  6.033588\n",
      "15    2015-08-05 06:00:00  6.007342\n",
      "16    2016-06-18 23:00:00  3.760328\n",
      "17    2014-07-31 02:00:00  4.530462\n",
      "18    2014-02-25 16:00:00  2.034354\n",
      "19    2017-07-10 00:00:00  4.271337\n",
      "20    2017-02-20 15:00:00  5.525524\n",
      "21    2014-06-16 11:00:00  4.997105\n",
      "22    2016-11-09 00:00:00  3.949631\n",
      "23    2015-09-01 00:00:00  5.083560\n",
      "24    2014-03-28 22:00:00  2.123763\n",
      "25    2015-11-25 09:00:00  5.127535\n",
      "26    2017-09-03 03:00:00  4.692445\n",
      "27    2015-11-20 12:00:00  4.923439\n",
      "28    2014-12-14 19:00:00  5.663519\n",
      "29    2018-03-21 00:00:00  2.835409\n",
      "...                   ...       ...\n",
      "7433  2017-10-15 12:00:00  4.154860\n",
      "7434  2017-12-09 11:00:00  5.488112\n",
      "7435  2014-09-15 01:00:00  4.687620\n",
      "7436  2017-02-16 16:00:00  5.936923\n",
      "7437  2014-10-23 13:00:00  5.408782\n",
      "7438  2015-11-13 20:00:00  5.429611\n",
      "7439  2016-12-08 07:00:00  4.979237\n",
      "7440  2017-03-23 00:00:00  3.563745\n",
      "7441  2015-09-13 22:00:00  3.109138\n",
      "7442  2014-04-18 11:00:00  2.398439\n",
      "7443  2017-06-16 22:00:00  4.950454\n",
      "7444  2014-02-05 16:00:00  1.478455\n",
      "7445  2018-04-25 17:00:00  4.136212\n",
      "7446  2017-10-03 07:00:00  6.536623\n",
      "7447  2014-09-06 01:00:00  5.745029\n",
      "7448  2018-03-26 11:00:00  5.161931\n",
      "7449  2017-07-20 00:00:00  4.732248\n",
      "7450  2017-03-09 06:00:00  5.620542\n",
      "7451  2017-07-21 14:00:00  4.902426\n",
      "7452  2016-09-18 16:00:00  3.733378\n",
      "7453  2014-11-04 10:00:00  5.404679\n",
      "7454  2016-12-15 16:00:00  7.013438\n",
      "7455  2015-10-26 12:00:00  5.768601\n",
      "7456  2014-12-31 08:00:00  5.232785\n",
      "7457  2017-03-23 00:00:00  4.271685\n",
      "7458  2017-10-08 00:00:00  4.533343\n",
      "7459  2017-10-12 05:00:00  5.209103\n",
      "7460  2017-02-17 03:00:00  5.248044\n",
      "7461  2014-02-21 22:00:00  2.934844\n",
      "7462  2016-08-20 08:00:00  4.476074\n",
      "\n",
      "[7463 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "output = model.predict(data=test_X)\n",
    "prediction = pd.DataFrame({'date': test_df['date'],'price': output })\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file generation\n",
    "prediction.to_csv(\"prediction.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
